---
title: Variational AutoEncoder (VAE)
date: 2023-08-24
tags: ["Variational AutoEncoder", "VAE"]
---

<style>
.textSingleImg {
  text-align: center;
}
.textTwoImg {
    display: flex;
    flex-direction: row;
    justify-content: space-around;

}
.singleImg {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.twoImg {
    display: inline;
    width: 300px;
    height: 300px;
    margin-left: 30px;
}
</style>



# Giới Thiệu

Variational AutoEncoder (VAE) là một biến thể của AutoEncoder models.

VAE là một loại “Generative Models” thuộc nhánh “Explicit Density Generative Models”.

Trong bài viết này, ta sẽ cùng đi tìm hiểu xem VAE hoạt động như nào nhé.

# AutoEncoder Tới VAE

Nhắc lại Traditional AE model

<img class="singleImg" src="/img/vae/1.jpg">

Như đã biết, Trong AE Model, Input X được đưa qua Encoder module để giảm chiều và học cách biểu diễn và lưu trữ tại “latent space Z”. Sau đó, “latent space Z” được giải mã để đưa ra output \\( \hat{X} \\) (là 1 biểu diễn giống với X nhất có thể với số chiều, kích thước đã được giảm đi”).

Do vậy, trong quá trình học của AE model, với mỗi điểm dữ liệu \\( x_i \\) in X. Model sẽ học 1 vector, để nắm bắt được các đặc trưng của dữ liệu \\( x_i \\) để có thể nén và biểu diễn \\( x_i \\) đó.

Khi đó với tập dữ liệu X, Sau khi model học xong, ta sẽ có một Ma trận trọng số “cố định” ứng với training dataset X. Thì với mỗi điểm dữ liệu \\( x_k \\) bất kỳ, thì model có thể dùng Ma trận trọng số để nén và biểu diễn lại \\( x_k \\) với số chiều nhỏ hơn là \\( \hat{x_k} \\) tương ứng.

Vấn đề ở đây là, AE model chỉ có thể nén và biểu diễn dữ liệu mà model đã được “quan sát” hay đã được học qua. Vì bộ trọng số sau khi học xong thì sẽ được “cố định”, thì chỉ có dữ liệu nào đã được quan sát thì AE mới có kiến thức về loại dữ liệu đó.

=> Khi đó, AE không thể nén và biểu diễn dữ liệu mà chưa được quan sát bao giờ.

Traditional AE model về bản chất chỉ nén và biểu diễn dữ liệu đã được quan sát, và không thể “sinh ra” dữ liệu mới chưa từng được quan sát.

## Variational AutoEncoder (VAE)

Giống với cách AutoRegressive model đã làm (mọi người có thể xem lại ở bài AutoRegressive trước đó).

VAE đưa ra giả thuyết với việc output (hay ở đây là input luôn, vì mục đích là \\( (\hat{X} \approx X) \\) sẽ tuân theo 1 phân phối \\( P_{\theta} \\) nào đó.

Và ta sẽ tạo ra \\( \hat{X} \\) với phân phối gần đúng của X là \\( P_{\theta}(X) \\) bằng việc sample từ phân phối \\( P_{\theta}(X) \\) đó.

Khi đó, thay vì học, tối ưu và mapping kiến thức vào vector cố định. VAE sẽ học bộ tham số \\( \theta \\) của phân phối \\( P_{\theta}(X) \\).

Giả sử bộ tham số \\( \theta^* \\) đã biết. Khi đó, để tạo được ra \\( \hat{X} \approx X \\),

Ta cần:

1.	Sample \\( z_i \\) từ phân phối \\( P_{\theta}(X) \\)
2.	Khi đó, ta sẽ có được \\( x_i \\) từ phân phối có điều kiện \\( P_{\theta}(X | Z = z_i) \\)

\\[ z \sim P_{\theta}(z) \\]
\\[ x \sim P_{\theta}(x|z) \\]

<img class="singleImg" src="/img/vae/2.jpg">

Các Latent variable Z, tạo ra Latent Space, để giúp trích rút các feature quan trọng của biến đầu vào X ban đầu, và biểu diễn X dưới biểu diễn có số chiều nhỏ hơn.

<img class="singleImg" src="/img/vae/3.jpg">

Đó là từ latent space để tạo ra dữ liệu \\( \hat{X} \approx X \\) (hay là phần decoder). Vậy từ việc input đầu vào X tới latent variable Z thì sao

Ta có:

\\[ x \sim P_{\theta}(x) \\]
\\[ z \sim P_{\theta}(z|x) \\]

Với Bayesian Rule ta có:

\\[ P_\theta(z|x) = {P_\theta(x|z) * P_\theta(z) \over P_\theta(x)} ~~~~~~~~~~~~~~~~ (1) \\]

Trong đó, ta có:

\\[ P_\theta(x, z) = P_\theta(x|z) P_\theta(z) \\]

Tích phân cả 2 vế với z ta có:

\\[ P_\theta(x) = \int_{z} P_\theta(x|z) P_\theta(z) dz ~~~~~~~~~~~~~~~~ (2)\\]

Tuy nhiên, rất là khó, dường như là ta sẽ không thể tính được \\( P_{\theta}(x|z) \\) cho mọi z tại phương trình (2) => phương trình (1) dường như cũng sẽ không thể tính được

Do vậy, Thay vì việc đi tìm phân phối không thể tìm được \\( P_{\theta}(z|x) \\), thì VAE tìm phân phối \\( q_{\varphi}(z|x) \approx p_{\theta}(z|x) \\).

Ta gọi:

\\[ f(p_\theta(x)) = log(p_\theta(x)) \\]

Ta có:

<hr/>

\\[ f'(p_\theta(x)) = {1 \over p_\theta(x)ln(2)} ~~~~~~~~, mà ~~~ ({1 \over x})' = - {x' \over x^2} \\]
\\[ \Rightarrow f"(p_\theta(x)) = - {1 \over \[p_\theta(x)\]^2ln(2)} < 0 ~~~~~~~~~(3)\\]
\\( (3) \Rightarrow f(p_\theta(x)) = log(p_\theta(x)) \\) là hàm **lõm** (concave function)

<hr/>

Ta có:

<hr/>

\\[ logp_\theta(x) = log \int_{z}p_\theta(x,z)dz \\]
\\[~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ = log \int_{z} p_\theta(x, z) {q_\varphi(z | x) \over q_\varphi(z | x)}dz \\]
\\[~~~~~~~~~~~~~~~~~~~ = log \mathbb{E_{q_\varphi(z | x)}}{p_\theta(x, z) \over q_\varphi(z | x)} \\]

<hr/>

Vì  \\( ~ logp_\theta(x) ~ \\)  là hàm **lõm**

=> Áp dụng bất đẳng thức "Jensen"

Ta có: \\( f(\mathbb{E}(x) \ge \mathbb{E}(f(x))) \\)

\\[ \Rightarrow log \mathbb{E_{q_\varphi(z | x)}}{p_\theta(x, z) \over q_\varphi(z | x)} \ge \mathbb{E_{q_\varphi(z|x)}}log\[{p_\theta(x,z) \over q_\varphi(z|x)}\] ~~~~~~~ (5) \\]

Đặt \\( ~ \mathcal{L_{\theta, \varphi}}(x) = \mathbb{E_{q_\varphi(z | x)}}log\[{p_\theta(x,z) \over q_\varphi(z|x)}\] ~ \\)

\\[ \Rightarrow logp_\theta(x) \ge \mathcal{L_{\theta, \varphi}}(x) ~~~~~ (*) \\]

Từ (5) ta có thể khai triển tiếp:

<hr/>

\\[ \mathcal{L_{\theta, \varphi}}(x) = \mathbb{E_{q_\varphi(z | x)}}log\[{p_\theta(x,z) \over q_\varphi(z|x)}\] \\]
\\[ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ = \int_{z}q_\varphi(z|x) log {p_theta(x, z)p_\theta(z|x) \over p_\theta(z|x)q_\varphi(z|x)} \\]
\\[~~~~~~~~~~~~~~ = \int_{z}q_\varphi(z|x)log{p_\theta(x) \over {q_\varphi(z|x) \over p_\theta(z|x)}}\\]
\\[ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~= logp_\theta(x) - \int_{z}q_\varphi(z|x)log{q_\varphi(z|x) \over p_\theta(z|x)} \\]

<hr/>

Ta có thể thấy:

\\(~~ \int_{z}q_\varphi(z|x)log{q_\varphi(z|x) \over p_\theta(z|x)} = KL(q_\varphi(z|x) || p_\theta(z|x)) \\)

\\( \Rightarrow \mathcal{L_{\theta, \varphi}}(x) = logp_\theta(x) - KL(q_\varphi(z|x) || p_\theta(z|x)) \\)

\\( \Rightarrow Maximum ~ \mathcal{L_{\theta, \varphi}}(x) = logp_\theta(x) \Leftrightarrow KL(q_\varphi(z|x) || p_\theta(z|x)) = 0 \\)

<hr/>

Mà KL (Kullback-Leibler) là 1 độ đo, đo sự khác nhau giữa 2 phân phối

\\[ KL(q_\varphi(z|x) || p_\theta(z|x)) = 0 \Leftrightarrow q_\varphi(z|x) = p_\theta(z|x) \\]

<hr/>

=> Ta có \\( \mathcal{L_{\theta, \varphi}}(x) \leq log P_{\theta}(x) \\) => Ta có thể tối đa hoá \\( \mathcal{L_{\theta, \varphi}}(x) \\) như một proxy cho việc tối đa hoá \\( logp_{\theta}(X) \\).

Và việc tối đa \\( \mathcal{L_{\theta, \varphi}}(x) \\) sẽ là học cả \\( q_{\varphi}(z|x) \\) và \\( P_{\theta}(x|z) \\) cùng nhau.

<hr/>

\\[ \mathcal{L_{\theta, \varphi}}(x) = \mathbb{E_{q_\varphi(z | x)}}log\[{p_\theta(x,z) \over q_\varphi(z|x)}\] \\]
\\[ ~~~~~~~~~~~~~~~~~~~~ = \mathbb{E_{q_\varphi(z|x)}}log{p_\theta(z)p_\theta(x|z) \over q_\varphi(z|x)} \\]

<hr/>

<img class="singleImg" src="/img/vae/4.jpg">

### Bài toán Maximization ELBO

Ok, giờ ta có bài toán Maximization ELBO hay \\( \mathcal{L_{\theta, \varphi}}(x) \\) ở đây. Như đã biết thì ta sẽ thực hiện sample z từ \\( q_{\varphi}(z|x) \\).

Giả sử ta có tập các mẫu z được samples từ \\( q_{\varphi}(z|x) \\) là \\( z^{(l)} \\), với l = 1, 2, …, L.

Ta có thể ước lượng ELBO với Monte Carlo như sau:

\\[ \mathcal{L_{\theta, \varphi}} \approx {1 \over L} \sum_{l=1}^{L} \[logp_\theta(x, z^{(l)}) - logq_\varphi(z^{(l)} | x)\] \\]

Với: \\[ ~ z^{(l)} \sim q_\varphi(z|x) \\]

Để có thể tìm được phi, theta để tối đa hoá ELBO. Ta sử dụng gradient ascent để tối ưu và cập Nhật các tham số theta và phi.

=> ta cần tính được đạo hàm riêng theo theta và phi của ELBO để có thể cập Nhật các tham số.

Tuy nhiên, có thể thấy, giá trị kỳ vọng \\( \mathbb{E_{q_{\varphi}(z|x)}} \\) được tính bằng tập samples từ \\( z \sim q_{\varphi}(z|x) \\). Trong khi đó, sample \\( z \sim q_{\varphi}(z|x) \\) là quá trình ngẫu nhiên và không thể thực hiện backpropagate được.

<img class="singleImg" src="/img/vae/5.jpg">

Do vậy, VAE đã đưa ra cách ước lượng hiệu quả hơn được gọi là “reparameterization trick”

### Reparameterization Trick

Để làm cho \\( z \sim q_{\varphi}(z|x) \\) có thể backpropagate và train được. VAE biểu diễn z dưới dạng biến xác định thông qua biến ngẫu nhiên phụ trợ \\( \mathcal{E} \\).

\\[ Z = \mathcal{T_\varphi}(x, \mathcal{E}) \\]

Với \\( \mathcal{E} \\) là biến ngẫu nhiên phụ trợ và \\( \mathcal{T}_{\varphi}(x, \mathcal{E}) \\) được tham số hoá bởi phi để biến \\( \mathcal{E} \\) thành \\( Z \\)

<img class="singleImg" src="/img/vae/6.jpg">

Giả thuyết được đưa ra là \\( z \sim \mathcal{N}(\mu, \sigma^2) \\), và \\( \mathcal{E} \sim \mathcal{N}(0, 1) \\).

Khi đó, ta có:

<img class="singleImg" src="/img/vae/7.jpg">

\\[ z \sim q_\varphi(z|x) = \mathcal{N}(z; \mu, \sigma^2) \\]
\\( ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ z = \mu + \sigma \odot \mathcal{E}~~ \\) , với \\( ~~ \mathcal{E} \sim \mathcal{N}(0, 1) \\)

Do vậy, \\( \mathcal{T}_{\varphi}(x, \mathcal{E}) \\) sẽ convert \\( \mathcal{E} \\) thành \\( z \\) bằng cách **scale** và **shift** \\( \mathcal{E} \\) được sample từ \\( \mathcal{N}(0, 1) \\)

Khi đó, model sẽ nhận đầu vào là \\( X \\) và học các tham số \\( \mu \\) và \\( \sigma^2 \\) để scale và shift chuyển \\( \mathcal{E} \\) thành \\( Z \\).

\\[ \mathcal{L_{\theta, \varphi}(x)} = \mathbb{E_{q_\varphi(z|x)}}\[ logp_\theta(x, z) - logq_\varphi(z|x) \] \\]
\\[~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ = {1 \over L} \sum_{l=1}^{L} \[logp_\theta(x, \mathcal{T_\varphi}(x, \mathcal{E^{(l)}})) - logq_\varphi(\mathcal{T_\varphi}(x, \mathcal{E^{(l)}}) | x)\] \\]

<img class="singleImg" src="/img/vae/8.jpg">
